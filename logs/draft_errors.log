2025-11-20T21:29:39.891911 - draft attempt failed (MAX_TOKENS) tokens=512 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 541\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T21:30:04.238028 - draft attempt failed (MAX_TOKENS) tokens=1024 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 1053\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T21:35:14.219977 - draft attempt failed (MAX_TOKENS) tokens=512 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 541\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T21:35:40.073949 - draft attempt failed (MAX_TOKENS) tokens=1024 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 1053\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T22:32:07.495024 - draft attempt failed (MAX_TOKENS) tokens=512 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 541\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T22:32:30.634932 - draft attempt failed (MAX_TOKENS) tokens=1024 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 1053\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T22:34:26.466207 - draft attempt failed (MAX_TOKENS) tokens=512 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 541\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T22:34:50.311935 - draft attempt failed (MAX_TOKENS) tokens=1024 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 1053\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T22:45:45.529599 - draft attempt failed (MAX_TOKENS) tokens=512 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 541\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T22:46:12.046478 - draft attempt failed (MAX_TOKENS) tokens=1024 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 1053\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T23:00:30.735635 - draft attempt failed (MAX_TOKENS) tokens=512 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 541\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T23:00:54.657845 - draft attempt failed (MAX_TOKENS) tokens=1024 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 1053\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T23:11:44.418252 - draft attempt failed (MAX_TOKENS) tokens=512 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 541\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T23:12:07.323533 - draft attempt failed (MAX_TOKENS) tokens=1024 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 1053\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T23:18:20.042602 - draft attempt failed (MAX_TOKENS) tokens=512 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 541\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T23:18:44.382383 - draft attempt failed (MAX_TOKENS) tokens=1024 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 1053\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-20T23:23:59.331238 - draft unexpected exception tokens=512 - exc=ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\nPlease retry in 5.773568119s.')
2025-11-20T23:24:06.350822 - draft unexpected exception tokens=1024 - exc=ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\nPlease retry in 58.702810339s.')
2025-11-20T23:24:13.337521 - draft unexpected exception tokens=1536 - exc=ResourceExhausted('You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash\nPlease retry in 51.714503732s.')
2025-11-20T23:24:13.338026 - draft all attempts failed for email_id=email_011. last_diag=429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. 
* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 250, model: gemini-2.5-flash
Please retry in 51.714503732s. [links {
  description: "Learn more about Gemini API quotas"
  url: "https://ai.google.dev/gemini-api/docs/rate-limits"
}
, violations {
  quota_metric: "generativelanguage.googleapis.com/generate_content_free_tier_requests"
  quota_id: "GenerateRequestsPerDayPerProjectPerModel-FreeTier"
  quota_dimensions {
    key: "model"
    value: "gemini-2.5-flash"
  }
  quota_dimensions {
    key: "location"
    value: "global"
  }
  quota_value: 250
}
, retry_delay {
  seconds: 51
}
]
2025-11-24T17:35:00.238609 - draft attempt failed (MAX_TOKENS) tokens=512 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 541\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-24T17:35:24.483118 - draft attempt failed (MAX_TOKENS) tokens=1024 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 1053\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-24T17:48:42.649853 - draft attempt failed (MAX_TOKENS) tokens=512 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 541\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-24T17:49:07.504122 - draft attempt failed (MAX_TOKENS) tokens=1024 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 1053\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-24T18:27:34.358882 - draft attempt failed (MAX_TOKENS) tokens=512 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 541\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-24T18:27:59.002832 - draft attempt failed (MAX_TOKENS) tokens=1024 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 1053\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-24T19:08:40.046440 - draft attempt failed (MAX_TOKENS) tokens=512 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 541\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-24T19:09:05.168549 - draft attempt failed (MAX_TOKENS) tokens=1024 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 1053\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-24T19:19:47.653552 - draft attempt failed (MAX_TOKENS) tokens=512 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 541\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
2025-11-24T19:20:12.297696 - draft attempt failed (MAX_TOKENS) tokens=1024 - diag=Model returned no extractable text. Diagnostics: {"note": "no extractable text from SDK response", "finish_reason": 2, "repr": "response:\nGenerateContentResponse(\n    done=True,\n    iterator=None,\n    result=protos.GenerateContentResponse({\n      \"candidates\": [\n        {\n          \"content\": {\n            \"role\": \"model\"\n          },\n          \"finish_reason\": \"MAX_TOKENS\",\n          \"index\": 0\n        }\n      ],\n      \"usage_metadata\": {\n        \"prompt_token_count\": 30,\n        \"total_token_count\": 1053\n      },\n      \"model_version\": \"gemini-2.5-flash\"\n    }),\n)"}
